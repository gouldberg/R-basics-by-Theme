plot(dat, xlab = "x", ylab = "y", main = paste0("r = ", round(cor(dat[,1], dat[,2]), 2)), cex.main = 2, cex = 1.2, pch = 20)
abline(h = 0, lty = 2, col = "gray")
abline(v = 0, lty = 2, col = "gray")
lines(smooth.spline(dat[,1], dat[,2]), col = "blue", lty = 2, lwd = 1)
}
( r <- seq(0, 0.9, by = 0.1) )
set.seed(122345)
for(i in 1:length(r)){
Sigma1 <- matrix(c(1, r[i], r[i], 1), ncol = 2)
dat <- mvrnorm(n = n1, mu = mu1, Sigma = Sigma1)
plot(dat, xlab = "x", ylab = "y", main = paste0("r = ", round(cor(dat[,1], dat[,2]), 2)), cex.main = 2, cex = 1.2, pch = 20)
abline(h = 0, lty = 2, col = "gray")
abline(v = 0, lty = 2, col = "gray")
lines(smooth.spline(dat[,1], dat[,2]), col = "blue", lty = 2, lwd = 1)
}
graphics.off()
par(mfrow = c(3,4))
set.seed(122345)
for(i in 1:length(r)){
Sigma1 <- matrix(c(1, r[i], r[i], 1), ncol = 2)
dat <- mvrnorm(n = n1, mu = mu1, Sigma = Sigma1)
plot(dat, xlab = "x", ylab = "y", main = paste0("r = ", round(cor(dat[,1], dat[,2]), 2)), cex.main = 2, cex = 1.2, pch = 20)
abline(h = 0, lty = 2, col = "gray")
abline(v = 0, lty = 2, col = "gray")
lines(smooth.spline(dat[,1], dat[,2]), col = "blue", lty = 2, lwd = 1)
}
graphics.off()
par(mfrow = c(3,4))
set.seed(122345)
for(i in 1:length(r)){
Sigma1 <- matrix(c(1, r[i], r[i], 1), ncol = 2)
dat <- mvrnorm(n = n1, mu = mu1, Sigma = Sigma1)
plot(dat, xlab = "x", ylab = "y", main = paste0("r = ", round(cor(dat[,1], dat[,2]), 2)), cex.main = 2, cex = 1.2, pch = 20)
abline(h = 0, lty = 2, col = "gray")
abline(v = 0, lty = 2, col = "gray")
lines(smooth.spline(dat[,1], dat[,2]), col = "blue", lty = 2, lwd = 1)
}
setwd("C:\\Users\\kswad\\OneDrive\\デスクトップ\\技術力強化_統計解析\\51_解析スクリプト\\00_basics\\02_correlation")
packages <- c("dplyr")
purrr::walk(packages, library, character.only = TRUE, warn.conflicts = FALSE)
# ------------------------------------------------------------------------------
# Read Anscombe's data
# ------------------------------------------------------------------------------
data <- read.csv("Anscombe_data.txt", header = T, stringsAsFactors = FALSE, sep = "\t")
str(data)
data
result1 <- lm(y1~x1, data=data)
r2_1 <- round(1 - var(resid(result1))/var(data$y1), 2)
result2 <- lm(y2~x2, data=data)
r2_2 <- round(1 - var(resid(result2))/var(data$y2), 2)
result3 <- lm(y3~x3, data=data)
r2_3 <- round(1 - var(resid(result3))/var(data$y3), 2)
result4 <- lm(y4~x4, data=data)
r2_4 <- round(1 - var(resid(result4))/var(data$y4), 2)
# ----------
op <- par(mfrow=c(2,2), mar=c(4,4,1,1), oma=c(0,0,2,0))
for(i in 1:4){
xname <- paste("x", i, sep="");  yname <- paste("y", i, sep="")
plot(data[,xname], data[,yname], xlim=c(0,20), ylim=c(0,20), xlab=xname, ylab=yname, pch = 20, cex = 2, col = "blue")
abline(eval(parse(text=paste("result", i, sep=""))), lty = 2)
mtext(paste("R^2=", eval(parse(text=paste("r2_", i, sep="")))), cex=1.5)
}
par(op)
# mean of 10 groups
dat_mean <- mvrnorm(n = 10, mu = c(0, 0), Sigma = matrix(c(1, 0.7, 0.7, 1), ncol = 2))
dat_mean <- data.frame(x = dat_mean[,1], y = dat_mean[,2], group = 1:10)
plot(y ~ x, groups = as.factor(group), data = dat_mean, pch = 20, cex = 3, col = "black",
main = paste0("10 groups mean, correlation is ", round(cor(dat_mean$x, dat_mean$y), 3)),
xlim = c(-4, 4), ylim = c(-4, 4), cex.main = 2)
abline(lm(y ~ x, data = dat_mean), lty = 2, col = "black")
par(mfrow = c(1,1))
dat_mean <- mvrnorm(n = 10, mu = c(0, 0), Sigma = matrix(c(1, 0.7, 0.7, 1), ncol = 2))
dat_mean <- data.frame(x = dat_mean[,1], y = dat_mean[,2], group = 1:10)
plot(y ~ x, groups = as.factor(group), data = dat_mean, pch = 20, cex = 3, col = "black",
main = paste0("10 groups mean, correlation is ", round(cor(dat_mean$x, dat_mean$y), 3)),
xlim = c(-4, 4), ylim = c(-4, 4), cex.main = 2)
abline(lm(y ~ x, data = dat_mean), lty = 2, col = "black")
abline(lm(y ~ x, data = dat_mean), lty = 2, col = "black")
par(mfrow = c(1,1))
dat_mean <- mvrnorm(n = 10, mu = c(0, 0), Sigma = matrix(c(1, 0.7, 0.7, 1), ncol = 2))
dat_mean <- data.frame(x = dat_mean[,1], y = dat_mean[,2], group = 1:10)
plot(y ~ x, data = dat_mean, pch = 20, cex = 3, col = "black",
main = paste0("10 groups mean, correlation is ", round(cor(dat_mean$x, dat_mean$y), 3)),
xlim = c(-4, 4), ylim = c(-4, 4), cex.main = 2)
abline(lm(y ~ x, data = dat_mean), lty = 2, col = "black")
n <- seq(30, 130, by = 10)
r <- c(-0.4, -0.3, -0.2, 0.3, 0.4, 0.8, 0.4, 0.3, 0.2, 0.4)
graphics.off()
par(mfrow = c(3,4))
set.seed(122345)
dat_all <- data.frame()
for(i in 1:length(r)){
Sigma1 <- matrix(c(1, r[i], r[i], 1), ncol = 2)
dat <- mvrnorm(n = n[i], mu = c(dat_mean[i,1], dat_mean[i,2]), Sigma = Sigma1)
tmp <- data.frame(x = dat[,1], y = dat[,2], group = i)
dat_all <- rbind(dat_all, tmp)
plot(dat, main = paste0("r = ", round(cor(dat[,1], dat[,2]), 2)), cex.main = 2, cex = 1.2, pch = 20)
abline(h = dat_mean[i,2], lty = 2, col = "black")
abline(v = dat_mean[i,1], lty = 2, col = "black")
}
dat_all
head(dat_all)
graphics.off()
plot(y ~ x, data = dat_all, pch = 1:10, col = 1:10,
main = paste0("Pearson Correlation: ", round(cor(dat_all$x, dat_all$y), 3)), cex = 1.2)
points(y ~ x, data = dat_mean, pch = 20, cex = 3, col = "black")
points(y ~ x, data = dat_mean, pch = 20, cex = 3, col = "black")
graphics.off()
plot(y ~ x, data = dat_all, pch = 1:10, col = 1:10,
main = paste0("Pearson Correlation: ", round(cor(dat_all$x, dat_all$y), 3)), cex = 1.2)
points(y ~ x, data = dat_mean, pch = 20, cex = 3, col = "black")
abline(lm(y ~ x, data = dat_all), lwd = 4, col = "black")
for(i in 1:10){ abline(lm(y ~ x, data = dat_all[dat_all$group == i,]), col = i) }
library(dplyr)
thre_y <- -2.0
thre_x <- -2.5
dat_all_cut <- dat_all %>% filter(x > thre_x, y > thre_y)
summary(dat_all_cut)
# dat_all_cut <- dat_all %>% filter(y > thre_y)
# ----------
graphics.off()
plot(y ~ x, data = dat_all_cut, pch = 1:10, col = 1:10,
main = paste0("Pearson Correlation: ", round(cor(dat_all_cut$x, dat_all_cut$y), 3)),
cex = 1.2, ylim = c(-4, 4), xlim = c(-4, 4), cex.main = 2)
points(y ~ x, data = dat_mean, pch = 20, cex = 3, col = "black")
round(cor(dat_all$x, dat_all$y), 3)
round(cor(dat_all_cut$x, dat_all_cut$y), 3)
library(nlme)
glin <- lm(y ~ x, data = dat_all)
summary(glin)
plot(y ~ x, data = dat_all)
abline(glin)
glin2 <- lm(y ~ x + group, data = dat_all)
summary(glin2)
glin2 <- lm(y ~ x + as.factor(group), data = dat_all)
summary(glin2)
lmemod1 <- lme(y ~ 1, random = ~ 1 | as.factor(group), data = dat_all)
summary(lmemod1)
F0 <- fitted(lmemod1, level = 0)
F1 <- fitted(lmemod1, level = 1)
I <- order(dat_all$x)
xs <- sort(dat_all$x)
plot(y ~ x, group = as.factor(dat_all$group), data = dat_all, pch = 1:10, col = 1:10)
lines(xs, F0[I], lwd = 4, type = "l")
for(i in 1:10){
x1 <- dat_all$x[dat_all$group == i]
y1 <- F1[dat_all$group == i]
K <- order(x1)
lines(sort(x1), y1[K])
}
library(nlme)
lmemod2 <- lme(y ~ x, random = ~ 1 | as.factor(group), data = dat_all)
summary(lmemod2)
summary(glin2)
# -->
# residual variance:  0.84 ^ 2, different from glin2 (1.025 ^ 2)
# variance for random intercept:  0.76 ^ 2
# fixed effects coefficients = 0.420, different from glin2 (0.448)
# ----------
F0 <- fitted(lmemod2, level = 0)
F1 <- fitted(lmemod2, level = 1)
I <- order(dat_all$x)
xs <- sort(dat_all$x)
plot(y ~ x, group = as.factor(dat_all$group), data = dat_all, pch = 1:10, col = 1:10)
lines(xs, F0[I], lwd = 4, type = "l")
for(i in 1:10){
x1 <- dat_all$x[dat_all$group == i]
y1 <- F1[dat_all$group == i]
K <- order(x1)
lines(sort(x1), y1[K])
}
lmemod3 <- lme(y ~ x, random = ~ 1 + x | as.factor(group), data = dat_all)
summary(lmemod3)
# -->
# residual variance:  0.83 ^ 2 (a little bit smaller)
# variance for random intercept:  0.71 ^ 2
# fixed effects coefficients = 0.420
# ----------
F0 <- fitted(lmemod3, level = 0)
F1 <- fitted(lmemod3, level = 1)
I <- order(dat_all$x)
xs <- sort(dat_all$x)
plot(y ~ x, group = as.factor(dat_all$group), data = dat_all, pch = 1:10, col = 1:10)
lines(xs, F0[I], lwd = 4, type = "l")
for(i in 1:10){
x1 <- dat_all$x[dat_all$group == i]
y1 <- F1[dat_all$group == i]
K <- order(x1)
lines(sort(x1), y1[K])
}
data <- read.csv("Anscombe_data.txt", header = T, stringsAsFactors = FALSE, sep = "\t")
str(data)
data
# ------------------------------------------------------------------------------
# data explorationo
# ------------------------------------------------------------------------------
summary(data)
# ------------------------------------------------------------------------------
# plot data
# ------------------------------------------------------------------------------
result1 <- lm(y1~x1, data=data)
r2_1 <- round(1 - var(resid(result1))/var(data$y1), 2)
result2 <- lm(y2~x2, data=data)
r2_2 <- round(1 - var(resid(result2))/var(data$y2), 2)
result3 <- lm(y3~x3, data=data)
r2_3 <- round(1 - var(resid(result3))/var(data$y3), 2)
result4 <- lm(y4~x4, data=data)
r2_4 <- round(1 - var(resid(result4))/var(data$y4), 2)
# ----------
op <- par(mfrow=c(2,2), mar=c(4,4,1,1), oma=c(0,0,2,0))
for(i in 1:4){
xname <- paste("x", i, sep="");  yname <- paste("y", i, sep="")
plot(data[,xname], data[,yname], xlim=c(0,20), ylim=c(0,20), xlab=xname, ylab=yname, pch = 20, cex = 2, col = "blue")
abline(eval(parse(text=paste("result", i, sep=""))), lty = 2)
mtext(paste("R^2=", eval(parse(text=paste("r2_", i, sep="")))), cex=1.5)
}
par(op)
# ----------
# Note that all models are significant ..
summary(result1)
summary(result2)
summary(result3)
summary(result4)
round(cor(data$x1, data$y1), 3)
round(cor(data$x2, data$y2), 3)
round(cor(data$x3, data$y3), 3)
round(cor(data$x4, data$y4), 3)
round(cor(data$x1, data$y1, method="spearman"), 3)
round(cor(data$x2, data$y2, method="spearman"), 3)
round(cor(data$x3, data$y3, method="spearman"), 3)
round(cor(data$x4, data$y4, method="spearman"), 3)
help(cor)
boss1_hyouka_gyoseki <- c(5, 3, 4, 1, 6, 2, 7, 8)
boss1_hyouka_sougou <- c(4, 3, 5, 2, 6, 1, 8, 7)
boss2_hyouka_gyoseki <- c(8, 4, 3, 1, 5, 2, 7, 6)
boss2_hyouka_sougou <- c(6, 2, 1, 4, 3, 7, 8, 5)
buka_id <- seq(1, 8, by = 1)
( df <- data.frame(buka_id, boss1_hyouka_gyoseki, boss1_hyouka_sougou, boss2_hyouka_gyoseki, boss2_hyouka_sougou) )
library(psych)
# Pearson, Spearman, Kendall correlation (tau-a)
psych::pairs.panels(df[,2:ncol(df)], method = "pearson")
psych::pairs.panels(df[,2:ncol(df)], method = "spearman")
psych::pairs.panels(df[,2:ncol(df)], method = "kendall")
library(psych)
# Pearson, Spearman, Kendall correlation (tau-a)
psych::pairs.panels(df[,2:ncol(df)], method = "pearson")
cor(boss1_hyouka_gyoseki, boss2_hyouka_gyoseki, method = "kendall")
cor(boss1_hyouka_sougou, boss2_hyouka_sougou, method = "kendall")
cor(boss1_hyouka_gyoseki, boss2_hyouka_gyoseki, method = "kendall")
cor(boss1_hyouka_sougou, boss2_hyouka_sougou, method = "kendall")
data(bock, package = "psych")
lsat6
dim(lsta6)
for(i in 1:dim(lsat6)[2]) print(table(lsat6[,i]))
lstat6
lsta6
library(mvtnorm)
set.seed(12345)
data <- rmvnorm(1000, c(0,0), matrix(c(1, 0.5, 0.5, 1), 2, 2))
x <- data[,1]
y <- data[,2]
# ----------
par(mfrow = c(1,1))
plot(x, y)
lines(smooth.spline(x, y), col = "blue", lty = 1)
cor(x, y, method = "pearson")
library(mvtnorm)
set.seed(12345)
data <- rmvnorm(1000, c(0,0), matrix(c(1, 0.5, 0.5, 1), 2, 2))
x <- data[,1]
y <- data[,2]
# ----------
par(mfrow = c(1,1))
plot(x, y)
lines(smooth.spline(x, y), col = "blue", lty = 1)
cor(x, y, method = "pearson")
y2 <- cut(y, c(-Inf, -1, Inf))
str(y2)
head(y2)
par(mfrow = c(1,1))
plot(x, y2)
plot(y2, x)
library(polycor)
polycor::polyserial(x, y2)
polycor::polyserial(x, y2, ML = TRUE, std.err = TRUE)
polycor::polyserial(x, y2, ML = TRUE, std.err = TRUE)
par(mfrow = c(1,1))
plot(x, y)
lines(smooth.spline(x, y), col = "blue", lty = 1)
y2 <- cut(y, c(-Inf, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, Inf))
str(y2)
par(mfrow = c(1,1))
plot(x, y2)
polycor::polyserial(x, y2)
polycor::polyserial(x, y2, ML = TRUE, std.err = TRUE)
y2 <- cut(y, c(-Inf, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, Inf))
summary(y)
y2
y
y2
quantile(y, prob = 0.95)
y
y[y <= qunatile(y, 0.95)]
y[y <= quantile(y, 0.95)]
quantile(y, 0.95)
y <= quantile(y, 0.95)
y[y <= quantile(y, 0.95)]
car::densityPlot(y)
library(polycor)
tetran <- polychor(x = item6_quali$古典, y = item6_quali$地学, std.err = TRUE, ML = TRUE)
tetran
# ----------
tetran$rho
tetran$row.cuts
tetran$col.cuts
round(tetran$var, 4)
# -->
# variance is very small, no problem for estimation
# ------------------------------------------------------------------------------
# polychoric correlation:  n * m  (at least one of n and m have 3 or more categories)
# ------------------------------------------------------------------------------
table(item6_quali[,c("古典", "現代文")])
pola <- polychor(x = item6_quali$古典, y = item6_quali$現代文, std.err = TRUE, ML = TRUE)
pola
# ----------
pola$rho
pola$row.cuts
pola$col.cuts
# -->
# 2 cut point for "現代文"
sleep
str(sleep)
head(sleep)
library(lattice)
histogram(~ extra | group, data = sleep)
par(mfrow = c(1,1))
boxplot(extra ~ group, data = sleep)
with(sleep, by(extra, group, mean))
( output1 <- shapiro.test(sleep$extra[sleep$group == 1]) )
( mu <- mean(sleep$extra[sleep$group == 1]) )
( sd <- sd(sleep$extra[sleep$group == 1]) )
( output2 <- ks.test(x = sleep$extra[sleep$group == 1], y = "pnorm", mean = mu, sd = sd, alternative = c("two.sided"), exact = TRUE) )
( mu <- mean(sleep$extra[sleep$group == 1]) )
( sd <- sd(sleep$extra[sleep$group == 1]) )
( output2 <- ks.test(x = sleep$extra[sleep$group == 1], y = "pnorm", mean = mu, sd = sd, alternative = c("two.sided"), exact = TRUE) )
output1$p.value
output2$p.value
output1$p.value
output2$p.value
( output1 <- shapiro.test(sleep$extra[sleep$group == 2]) )
# ----------
# Kolmogrov - Smirnov Normality Test
( mu <- mean(sleep$extra[sleep$group == 2]) )
( sd <- sd(sleep$extra[sleep$group == 2]) )
( output2 <- ks.test(x = sleep$extra[sleep$group == 2], y = "pnorm", mean = mu, sd = sd, alternative = c("two.sided"), exact = TRUE) )
# ----------
# Both tests does NOT REJECTED
output1$p.value
output2$p.value
graphics.off()
par(mfrow = c(1,2))
qqnorm(sleep$extra[sleep$group == 1])
qqline(sleep$extra[sleep$group == 1])
qqnorm(sleep$extra[sleep$group == 2])
qqline(sleep$extra[sleep$group == 2])
( output <- t.test(sleep$extra[sleep$group == 1], mu = 1, alternative = c("two.sided")) )
( output <- t.test(sleep$extra[sleep$group == 1], mu = 1, alternative = c("two.sided")) )
output$p.value
par(mfrow = c(1,1))
boxplot(extra ~ group, data = sleep)
with(sleep, by(extra, group, mean))
( output <- t.test(sleep$extra[sleep$group == 1], mu = 1, alternative = c("two.sided")) )
output$p.value
( output <- var.test(extra ~ group, data = sleep) )
( output <- t.test(extra ~ group, data = sleep, alternative = c("two.sided")) )
output$p.value
beta <- 0.2
( Zb <- qnorm(p = beta, mean = 0, sd = 1) )
alpha <- 0.05
( Z2a <- qnorm(p = 1 - alpha / 2, mean = 0, sd = 1) )
sd_common <- 0.5
effect_size <- sd_common * 0.2
( n <- ceiling(2 * (Z2a - Zb) ^ 2 * sd_common ^ 2 / (effect_size ^ 2) ) )
sd_common <- 0.5
effect_size <- sd_common * 0.2
( n <- ceiling(2 * (Z2a - Zb) ^ 2 * sd_common ^ 2 / (effect_size ^ 2) ) )
( A <- Z2a * sqrt(2) * sd_common / sqrt(n) )
( B <- Zb * sqrt(2) * sd_common / sqrt(n) )
( A - B )
effect_size
mu_h0 <- 5.0
( mu_h1 <- mu_h0 + effect_size )
( mu_h1 <- mu_h0 + effect_size )
dat_h0 <- rnorm(n = n, mean = mu_h0, sd = sd_common)
dat_h1 <- rnorm(n = n, mean = mu_h1, sd = sd_common)
min_all <- min(c(dat_h0, dat_h1))
max_all <- max(c(dat_h0, dat_h1))
par(mfrow = c(2,1))
brk <- seq(min_all - 0.1, max_all + 0.1, by = 0.1)
hist(dat_h0, breaks = brk)
abline(v = mu_h0, lty = 1, col = c("black"), lwd = 2)
hist(dat_h1, breaks = brk)
abline(v = mu_h1, lty = 1, col = c("black"), lwd = 2)
min_all <- min(c(dat_h0, dat_h1))
max_all <- max(c(dat_h0, dat_h1))
par(mfrow = c(2,1))
brk <- seq(min_all - 0.1, max_all + 0.1, by = 0.1)
hist(dat_h0, breaks = brk)
abline(v = mu_h0, lty = 1, col = c("black"), lwd = 2)
hist(dat_h1, breaks = brk)
abline(v = mu_h1, lty = 1, col = c("black"), lwd = 2)
myfunc <- function(n, mean, sd){
dat <- rnorm(n = n, mean = mean, sd = sd)
return(mean(dat))
}
# group 1
dat_h0_g1_mean <- sapply(1:10000, function(x) { myfunc(n = n, mean = mu_h0, sd = sd_common) })
# group 2 at H0
dat_h0_g2_mean <- sapply(1:10000, function(x) { myfunc(n = n, mean = mu_h0, sd = sd_common) })
# group 2 at H1
dat_h1_g2_mean <- sapply(1:10000, function(x) { myfunc(n = n, mean = mu_h1, sd = sd_common) })
dat_h0_g2_mean <- sapply(1:10000, function(x) { myfunc(n = n, mean = mu_h0, sd = sd_common) })
dat_h1_g2_mean <- sapply(1:10000, function(x) { myfunc(n = n, mean = mu_h1, sd = sd_common) })
diff_h0 <- dat_h0_g2_mean - dat_h0_g1_mean
diff_h1 <- dat_h1_g2_mean - dat_h0_g1_mean
sd(diff_h0)
sd(diff_h1)
sqrt(2) * sd_common / sqrt(n)
sum(diff_h0 > A) / length(diff_h0)
# H1:  beta
sum(diff_h1 < A) / length(diff_h1)
beta
A
sum(diff_h0 > A) / length(diff_h0)
sum(diff_h1 < A) / length(diff_h1)
sum(diff_h1 < A) / length(diff_h1)
beta
min_all <- min(c(diff_h0, diff_h1))
max_all <- max(c(diff_h0, diff_h1))
graphics.off()
par(mfrow = c(2,1))
brk <- seq(min_all - 0.1, max_all + 0.1, by = 0.01)
hist(diff_h0, breaks = brk, main = paste0("diff of means of H0, alpha/2 = ", round(alpha/2, 3)))
abline(v = c(0, A), lty = 1, col = c("black", "blue"), lwd = 2)
hist(diff_h1, breaks = brk, main = paste0("diff of means at H1, beta = ", round(beta, 3)))
abline(v = c(A, effect_size), lty = 1, col = c("blue", "black"), lwd = 2)
n <- 10
# ------------------------------------------------------------------------------
# effect size validation
# ------------------------------------------------------------------------------
( A <- Z2a * sqrt(2) * sd_common / sqrt(n) )
( B <- Zb * sqrt(2) * sd_common / sqrt(n) )
( A - B )
effect_size
# ------------------------------------------------------------------------------
# mu of h0 and h1
# ------------------------------------------------------------------------------
mu_h0 <- 5.0
( mu_h1 <- mu_h0 + effect_size )
# ( mu_h12 <- ( Z2a * sqrt(2) * sd_common + Zb * sqrt(2) * sd_common ) / sqrt(n) )
# ------------------------------------------------------------------------------
# simulation of one sample
# ------------------------------------------------------------------------------
dat_h0 <- rnorm(n = n, mean = mu_h0, sd = sd_common)
dat_h1 <- rnorm(n = n, mean = mu_h1, sd = sd_common)
# ----------
min_all <- min(c(dat_h0, dat_h1))
max_all <- max(c(dat_h0, dat_h1))
par(mfrow = c(2,1))
brk <- seq(min_all - 0.1, max_all + 0.1, by = 0.1)
hist(dat_h0, breaks = brk)
abline(v = mu_h0, lty = 1, col = c("black"), lwd = 2)
hist(dat_h1, breaks = brk)
abline(v = mu_h1, lty = 1, col = c("black"), lwd = 2)
# ------------------------------------------------------------------------------
# distribution of difference of means
# ------------------------------------------------------------------------------
myfunc <- function(n, mean, sd){
dat <- rnorm(n = n, mean = mean, sd = sd)
return(mean(dat))
}
# group 1
dat_h0_g1_mean <- sapply(1:10000, function(x) { myfunc(n = n, mean = mu_h0, sd = sd_common) })
# group 2 at H0
dat_h0_g2_mean <- sapply(1:10000, function(x) { myfunc(n = n, mean = mu_h0, sd = sd_common) })
# group 2 at H1
dat_h1_g2_mean <- sapply(1:10000, function(x) { myfunc(n = n, mean = mu_h1, sd = sd_common) })
# ----------
# difference of means
diff_h0 <- dat_h0_g2_mean - dat_h0_g1_mean
diff_h1 <- dat_h1_g2_mean - dat_h0_g1_mean
# ----------
# standard deviation of differences
sd(diff_h0)
sd(diff_h1)
sqrt(2) * sd_common / sqrt(n)
# ----------
# H0:  alpha / 2
sum(diff_h0 > A) / length(diff_h0)
# H1:  beta
sum(diff_h1 < A) / length(diff_h1)
beta
# ----------
min_all <- min(c(diff_h0, diff_h1))
max_all <- max(c(diff_h0, diff_h1))
graphics.off()
par(mfrow = c(2,1))
brk <- seq(min_all - 0.1, max_all + 0.1, by = 0.01)
hist(diff_h0, breaks = brk, main = paste0("diff of means of H0, alpha/2 = ", round(alpha/2, 3)))
abline(v = c(0, A), lty = 1, col = c("black", "blue"), lwd = 2)
hist(diff_h1, breaks = brk, main = paste0("diff of means at H1, beta = ", round(beta, 3)))
abline(v = c(A, effect_size), lty = 1, col = c("blue", "black"), lwd = 2)
